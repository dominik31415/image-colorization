{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from multiprocessing import Queue, Process\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') #for using this notebook as script\n",
    "from IPython import display as jupyter\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# load global constants\n",
    "from definitions_main import *\n",
    "\n",
    "import data_utils\n",
    "data_utils.init(\"definitions_main\")\n",
    "\n",
    "import model_utils\n",
    "model_utils.init(\"definitions_main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate various models\n",
    "# pre_generator : compiled generator model, using traditional training with cross-entropy\n",
    "# generator_trainer : compiled, generator with non-trainable critic\n",
    "# critic_trainer : compiled, critic with non-trainble generator\n",
    "pre_generator, generator, generator_trainer, critic, critic_trainer = model_utils.generate_and_compile_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous weights if they exist\n",
    "generator.load_weights(\"generator.model\") \n",
    "critic.load_weights(\"d:/downloads/models/wgan_c/cultivated/3/critic.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate data queues (launches about 6 additional processes)\n",
    "full_images_queue, only_L_ch_queue = Queue(20), Queue(5)\n",
    "tasks = data_utils.populate_trainer_queues(full_images_queue, only_L_ch_queue) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates probability for a sample to be positive, based on Cantelli's inequality and a list of i.i.d. samples\n",
    "def probability_for_positive(threshold, samples):\n",
    "    cut =  int(np.ceil(len(samples)/3))\n",
    "    mu = np.mean(samples[cut:])\n",
    "    var = np.var(samples[cut:])/(len(samples)-cut)\n",
    "    p = 1 - var/(mu**2 +var)\n",
    "    return p > threshold and mu > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras always needs #sample target values, even when model loss does not need it\n",
    "dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32) \n",
    "positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "negative_y = -np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "\n",
    "critic_loss = []\n",
    "generator_loss = []\n",
    "\n",
    "# The generator is always trained for #GENERATOR_ITERATIONS per loop, \n",
    "# but the ciritic is trained for #training_ratio iterations, which is dynamically determined based on its performnace:\n",
    "# when it performs well the ratio is decreased, when it performs poorly the ratio is increased\n",
    "training_ratio = CRITIC_ITERATIONS_INIT\n",
    "\n",
    "critic_iterations, generator_iterations = 0,0\n",
    "for outer_loop in range(100000):\n",
    "    jupyter.clear_output(wait=True)\n",
    "    print(\"Queue status: full images %d, L images %d\" % \n",
    "          (full_images_queue.qsize(), only_L_ch_queue.qsize()) )\n",
    "    print(\"Total iterations. Critic: %d, Generator: %d, Outer loop: %d\" %(critic_iterations, generator_iterations, outer_loop))\n",
    "    print(\"Training ratio Critic-Generator %d\" % training_ratio)    \n",
    "\n",
    "    # go through training_ratio minibatches for one iteration of discriminator training\n",
    "    w_distances = []\n",
    "    for j in range(training_ratio):        \n",
    "        critic_iterations+=1\n",
    "        # train critic\n",
    "        real_image_batch = full_images_queue.get()\n",
    "        L_batch = real_image_batch[:,:,:,0].reshape(BATCH_SHAPE_1)\n",
    "        # optimizes for low real score and high fake score --> low score means less real\n",
    "        loss = critic_trainer.train_on_batch([real_image_batch, L_batch], [negative_y, positive_y, positive_y])\n",
    "        critic_loss.append(loss)\n",
    "\n",
    "        critic_score_real_images = -loss[1]\n",
    "        critic_score_fake_images = loss[2]\n",
    "        gp_loss = loss[3]\n",
    "        score_gap = critic_score_real_images - critic_score_fake_images\n",
    "        w_distances.append(score_gap)\n",
    "        print(\"Wasserstein distance (aestimate) = %f, Score real image= %f, Gradient penalty = %f\" % (score_gap, critic_score_real_images, gp_loss))\n",
    "\n",
    "\n",
    "    # train generator\n",
    "    # only train generator when we can expect the wasserstein distance to be positive\n",
    "    if probability_for_positive(THRESHOLD_A, w_distances):\n",
    "        for m in range(GENERATOR_ITERATIONS):\n",
    "            generator_iterations+=1\n",
    "            L_batch = only_L_ch_queue.get()\n",
    "            # optimizes for high score --> tries to make it more real\n",
    "            loss = generator_trainer.train_on_batch(L_batch, negative_y)\n",
    "            fake_images_score = -loss\n",
    "            print(\"Adverserial training loss %f\" % fake_images_score)\n",
    "            generator_loss.append(loss)\n",
    "    else:\n",
    "        print(\"Skip generator training since crtic does not perform well.\")\n",
    "\n",
    "    # training schedule management\n",
    "    # if score is below target, spend more time on critic, otherwise spend less time on critic\n",
    "    if probability_for_positive(THRESHOLD_B, w_distances):\n",
    "        # critic performs well >> reduce the training ratio\n",
    "        training_ratio = max(training_ratio - 1, CRITIC_ITERATIONS_MIN)\n",
    "    else:\n",
    "        # critic performs poolry >> increase the training ratio\n",
    "        training_ratio = min(training_ratio + 1, CRITIC_ITERATIONS_MAX)\n",
    "\n",
    "    if outer_loop % 25 == 0:\n",
    "        # save some sample image results, the models and the accumulated statistics\n",
    "        data_utils.save_continuous_images(full_images_queue, generator) \n",
    "        generator.save(\"generator.model\") \n",
    "        critic.save(\"critic.model\")\n",
    "        np.savetxt(\"generator_loss.txt\", generator_loss)\n",
    "        np.savetxt(\"critic_loss.txt\", critic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
